---
# Probe every upstream account with retries; tolerate non-200 and non-JSON
- name: Upstream Accounts | Test Connect to Each Upstream Account (retry)
  ansible.builtin.uri:
    url: "{{ item.0.url | trim }}/player_api.php?username={{ item.1.username }}&password={{ item.1.password }}"
    method: GET
    return_content: true               # we want .json when available
    headers:
      Accept: "application/json, */*"
    timeout: 15
    validate_certs: false
  register: __probe
  loop: "{{ role_iptvservice__credentials | subelements('provider_credentials') }}"
  loop_control:
    label: "Checking {{ item.0.name }} :: {{ item.1.account }} @ {{ item.0.url }}"
  retries: 5
  delay: 10
  until: __probe.status is defined and __probe.status == 200
  ignore_errors: true

# Normalize results robustly (no blind .active_cons deref)
- name: Upstream Accounts | Normalize results
  ansible.builtin.set_fact:
    __upstream_results: >-
      {%- set out = [] -%}
      {%- for r in (__probe.results | default([])) -%}
        {%- set prov = r.item.0 -%}
        {%- set cred = r.item.1 -%}
        {%- set js = (r.json if (r.json is defined and r.json is mapping) else {}) -%}
        {%- set ui = js.get('user_info', {}) -%}
        {%- set si = js.get('server_info', {}) -%}
        {%- set rec = {
              'provider': prov.name,
              'provider_url': prov.url,
              'account':  cred.account,
              'username': cred.username,
              'password': cred.password,
              'status':   r.status | default(None),
              'ok':       (r.status | default(0)) == 200 and (ui.get('auth') in [1, '1', True]),
              'auth':     ui.get('auth'),
              'active_cons': ui.get('active_cons'),
              'max_connections': ui.get('max_connections'),
              'server_now': si.get('time_now'),
              'server_url': si.get('url'),
              'message': ui.get('message') or r.msg | default('')
            } -%}
        {%- set _ = out.append(rec) -%}
      {%- endfor -%}
      {{ out }}

# Convenience splits
- name: Upstream Accounts | Split success/failure
  ansible.builtin.set_fact:
    __successful_upstreams: "{{ __upstream_results | selectattr('ok') | list }}"
    __failed_upstreams: "{{ __upstream_results | rejectattr('ok') | list }}"

# Identify overloaded among successful (>=, not ==)
- name: Upstream Accounts | Identify overloaded successful accounts
  ansible.builtin.set_fact:
    __overloaded_upstreams: >-
      {%- set out = [] -%}
      {%- for it in __successful_upstreams -%}
        {%- if (it.active_cons is not none) and (it.max_connections is not none)
               and ((it.active_cons | int) >= (it.max_connections | int)) -%}
          {%- set _ = out.append(it) -%}
        {%- endif -%}
      {%- endfor -%}
      {{ out }}

# Simple visibility
- name: Upstream Accounts | Report successful upstreams
  ansible.builtin.debug:
    msg: "{{ item.account }} / {{ item.username }} @ {{ item.provider_url }} :: {{ item.active_cons | default('NA')
      }}/{{ item.max_connections | default('NA') }} active"
  loop: "{{ __successful_upstreams }}"
  loop_control:
    label: "OK {{ item.account }}"

- name: Upstream Accounts | Report failed upstreams
  ansible.builtin.debug:
    msg: "FAILED {{ item.account }} / {{ item.username }} @ {{ item.provider_url }} :: status={{ item.status }} auth={{ item.auth | default('NA')
      }} msg={{ item.message | default('') }}"
  loop: "{{ __failed_upstreams }}"
  loop_control:
    label: "FAIL {{ item.account }}"

# ---------- Kill mode: purge failed accounts ----------
# We remove their iptv-proxy processes and drop them from backends.json so the auth app stops routing to them.
- name: Upstream Accounts | Build path to backends.json
  ansible.builtin.set_fact:
    __backends_json_path: "{{ role_iptvservice__auth_root | trim }}/backends.json"

- name: Upstream Accounts | Load current backends.json
  ansible.builtin.slurp:
    src: "{{ __backends_json_path }}"
  register: __backends_b64
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__failed_upstreams | length) > 0

- name: Upstream Accounts | Parse current backends.json
  ansible.builtin.set_fact:
    __backends_current: "{{ (__backends_b64.content | b64decode | from_json) | default([], true) }}"
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__failed_upstreams | length) > 0

# Map failed accounts -> ports from backends.json (ports are what your iptv-proxy binds to)
- name: Upstream Accounts | Ports for failed accounts
  ansible.builtin.set_fact:
    __failed_accounts: "{{ __failed_upstreams | map(attribute='account') | list }}"
    __ports_to_kill: >-
      {%- set out = [] -%}
      {%- for b in __backends_current | default([]) -%}
        {%- if b.account in __failed_accounts -%}
          {%- set _ = out.append(b.port) -%}
        {%- endif -%}
      {%- endfor -%}
      {{ out | unique }}
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__failed_upstreams | length) > 0

# Kill processes by port
- name: Upstream Accounts | Find iptv-proxy PIDs by port
  community.general.pids:
    pattern: "/usr/bin/iptv-proxy.*--port {{ item }}"
  become: true
  loop: "{{ __ports_to_kill | default([]) }}"
  loop_control:
    label: "Find iptv-proxy on :{{ item }}"
  register: __pids_by_port
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__ports_to_kill | default([]) | length) > 0

- name: Upstream Accounts | Kill iptv-proxy PIDs
  ansible.builtin.command:
    cmd: "kill -9 {{ item.pids | join(' ') }}"
  become: true
  loop: "{{ __pids_by_port.results | default([]) }}"
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - item.pids is defined
    - item.pids | length > 0
  changed_when: true
  loop_control:
    label: "Killed {{ item.pids | join(', ') }}"

# Optional: firewall adjust (if you manage it here)
- name: Upstream Accounts | Remove iptables ACCEPT for failed ports
  ansible.builtin.iptables:
    chain: INPUT
    protocol: tcp
    destination_port: "{{ item }}"
    jump: ACCEPT
    state: absent
  become: true
  loop: "{{ __ports_to_kill | default([]) }}"
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - role_iptvservice__manage_firewall | default(true) | bool

- name: Upstream Accounts | Add iptables REJECT for failed ports
  ansible.builtin.iptables:
    chain: INPUT
    protocol: tcp
    destination_port: "{{ item }}"
    jump: REJECT
    reject_with: icmp-port-unreachable
    state: present
  become: true
  loop: "{{ __ports_to_kill | default([]) }}"
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - role_iptvservice__manage_firewall | default(true) | bool

# Write filtered backends.json (drop failed accounts) and restart auth so it re-reads
- name: Upstream Accounts | Compute remaining backends (remove failed accounts)
  ansible.builtin.set_fact:
    __backends_remaining: >-
      {%- set out = [] -%}
      {%- set drop = __failed_accounts | default([]) -%}
      {%- for b in __backends_current | default([]) -%}
        {%- if b.account not in drop -%}
          {%- set _ = out.append(b) -%}
        {%- endif -%}
      {%- endfor -%}
      {{ out }}
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__failed_upstreams | length) > 0

- name: Upstream Accounts | Save backends.json without failed accounts
  ansible.builtin.copy:
    dest: "{{ __backends_json_path }}"
    content: "{{ __backends_remaining | to_nice_json }}"
    mode: '0640'
    owner: root
    group: root
  when:
    - role_iptvservice__kill_mode | default(false) | bool
    - (__failed_upstreams | length) > 0
  notify:
    - Restart iptv-auth

# ---------- Email reports ----------
- name: Upstream Accounts | Email overloaded (warning)
  community.general.mail:
    from: "{{ role_iptvservice__email_sender }}"
    to: "{{ role_iptvservice__email_recipients }}"
    subject: "Warning: Upstreams nearing or at capacity"
    host: "{{ role_iptvservice__email_server }}"
    port: 25
    secure: never
    subtype: html
    body: |-
      <p>The following upstream accounts are at/over capacity:</p>
      <ul>
      {% for it in __overloaded_upstreams %}
        <li>
          <strong>{{ it.provider }}</strong> — {{ it.account }}
          &nbsp;@&nbsp;{{ it.provider_url }} :
          {{ it.active_cons }}/{{ it.max_connections }}
        </li>
      {% endfor %}
      </ul>
  when: (__overloaded_upstreams | length) > 0

- name: Upstream Accounts | Email failed upstreams
  community.general.mail:
    from: "{{ role_iptvservice__email_sender }}"
    to: "{{ role_iptvservice__email_recipients }}"
    subject: >-
      {% if role_iptvservice__kill_mode | default(false) | bool %}
      URGENT: Upstreams removed from IPTV Proxy
      {% else %}
      Alert: Upstream account(s) unreachable
      {% endif %}
    host: "{{ role_iptvservice__email_server }}"
    port: 25
    secure: never
    subtype: html
    body: |-
      <p>The following upstream accounts failed health checks:</p>
      <ul>
      {% for it in __failed_upstreams %}
        <li>
          <strong>{{ it.provider }}</strong> — {{ it.account }} ({{ it.username }})<br>
          URL: {{ it.provider_url }}<br>
          Status: {{ it.status }} | Auth: {{ it.auth | default('N/A') }}<br>
          Msg: {{ it.message | default('') }}
        </li>
      {% endfor %}
      </ul>
      {% if role_iptvservice__kill_mode | default(false) | bool %}
      <p><em>Kill mode was enabled.</em> The corresponding iptv-proxy processes were terminated,
      ports quarantined{{ ' (iptables)' if role_iptvservice__manage_firewall | default(true) | bool else '' }},
      and the accounts were removed from backends.json.</p>
      {% endif %}
  when: (__failed_upstreams | length) > 0
